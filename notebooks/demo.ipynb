import sys
import os

# 1. Environment Setup and Package Import
# --- Path Setup ---
# Add the project root to sys.path to allow importing the 'quirky' package 
# when running from the 'notebooks' sub-directory.
project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))
if project_root not in sys.path:
    sys.path.append(project_root)
    print(f"Added project root to path: {project_root}")

# --- Package Imports ---
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import shap

# Import the core Quirky class
from quirky.quirky import Quirky 
from sklearn.datasets import make_blobs
from typing import List, Tuple, Union, Any

# --- Jupyter Configuration ---
shap.initjs() 
sns.set_theme(style="whitegrid", palette="viridis")
# Ensure Matplotlib plots are displayed inline
%matplotlib inline 
print("\nEnvironment ready and Quirky class imported.")

# 2. Data Preparation and Function Definition
# --- Data Generation Function (Demo Specific) ---
def generate_demo_data(feature_names: List[str], n_normal: int = 1000, n_outliers: int = 50, random_state: int = 42) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """Generates a 2D dataset with a central cluster (normal) and points far away (anomalies)."""
    np.random.seed(random_state)
    
    # Normal Data (Used for clean training set)
    X_train_array, _ = make_blobs(n_samples=n_normal, n_features=2, centers=1, cluster_std=2.0, random_state=random_state)
    X_train_df = pd.DataFrame(X_train_array, columns=feature_names)
    
    # Anomalies (Out-of-range cluster for Transaction_Amount)
    X_outliers_F1 = np.random.uniform(low=20, high=30, size=(n_outliers, 1)) 
    X_outliers_F2 = np.random.uniform(low=7, high=10, size=(n_outliers, 1))  
    X_outliers_array = np.hstack([X_outliers_F1, X_outliers_F2])
    X_outliers_df = pd.DataFrame(X_outliers_array, columns=feature_names)

    # Full Data (Includes True Labels for Validation)
    X_full_df = pd.concat([X_train_df, X_outliers_df], ignore_index=True)
    X_full_df['True_Anomaly'] = np.array([0] * n_normal + [1] * n_outliers)
    X_full_df['True_Anomaly_Label'] = X_full_df['True_Anomaly'].map({0: 'Normal', 1: 'Anomaly'})

    return X_full_df, X_train_df

# --- Configuration ---
MODEL_FEATURES = ['Transaction_Amount', 'Login_Duration']
CONTAMINATION_RATE = 0.05
RANDOM_STATE = 42

# 3. Execution, Training, and Scoring
# 3a. Generate Data
full_data, train_data = generate_demo_data(MODEL_FEATURES, random_state=RANDOM_STATE)

# 3b. Initialize Detector
detector = Quirky(
    feature_names=MODEL_FEATURES,
    cont_rate=CONTAMINATION_RATE, 
    random_state=RANDOM_STATE
)

# 3c. Run Core Workflow
detector.load_data(X_full=full_data, X_train=train_data)
detector.train_model()
detector.calculate_scores()

# 3d. Get and display the feature values for the top predicted anomalies
results_df = detector.get_analysis_results()
print("\n--- Feature Values for Top 5 Predicted Anomalies (Lowest Scores) ---")
top_anomalies = results_df[results_df['Predicted_Anomaly'] == 1].sort_values('iForest_Score').head(5)

# Join back with the original feature data for inspection
anomaly_data = full_data.loc[top_anomalies.index].copy()
anomaly_data = anomaly_data.join(top_anomalies[['iForest_Score', 'Predicted_Anomaly']])

display(anomaly_data)

# 4. Visualization and Explanation
print("\n--- Generating Validation Figures (EDA and Model Checks) ---")
validation_figures = detector.get_validation_figures()

print("\n--- Generating SHAP Analysis Figures (Model Interpretation) ---")
analysis_figures = detector.run_shap_analysis()

# Combine and Display Figures
all_figures = {**validation_figures, **analysis_figures}

print(f"\nDisplaying {len(all_figures)} generated outputs...")

for name, output in all_figures.items():
    print(f"\n[OUTPUT] {name.replace('_', ' ').title()}")
    
    # SHAP force_plot returns a JS/HTML object, which displays automatically
    if name == 'force_plot':
        display(output)
    
    # Matplotlib figures (Validation, Bar, Beeswarm, Dependence)
    else:
        display(output)
        # Crucial for memory management in Jupyter: close the figure after display
        plt.close(output)
